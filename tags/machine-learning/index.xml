<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Digital Forays</title><link>https://kspicer80.github.io/tags/machine-learning/</link><description>Recent content in machine learning on Digital Forays</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Tue, 25 Apr 2023 00:01:00 +0000</lastBuildDate><atom:link href="https://kspicer80.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Digital Rhetoric and Predictive Machine Learning Models on Twitter Data</title><link>https://kspicer80.github.io/posts/2023-04-25-measuring-twitter-engagement-and-digital-rhetoric/</link><pubDate>Tue, 25 Apr 2023 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2023-04-25-measuring-twitter-engagement-and-digital-rhetoric/</guid><description>Recently I came across a wonderful YouTube Channel, Arjan Codes, and I have already learned a great deal from many of his videos, tutorials, etc.
Python Type Hints In my ENGE 515: Digital Rhetoric graduate-level course currently running (full list of courses is available through the USF REAL program, housed within the College of Education), we have been getting our feet wet in this field of rhetoric focused on the realm/world of &amp;ldquo;the digital&amp;rdquo; (I do notice too now—somehow it had slipped my mind—that I wrote a little bit already about how this course went last summer).</description></item><item><title>Predictive Modeling with the 'OK Cupid' Dataset</title><link>https://kspicer80.github.io/posts/2023-04-15-machine-learning-with-ok-cupid-dataset/</link><pubDate>Sat, 15 Apr 2023 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2023-04-15-machine-learning-with-ok-cupid-dataset/</guid><description>The final project for Codecademy&amp;rsquo;s &amp;ldquo;Building a Machine Learning Model with Python&amp;rdquo; Skill Path asks students to do a little work with the &amp;ldquo;OK Cupid&amp;rdquo; dataset—the project is humorously, punningly titled: &amp;ldquo;Date-A-Scientist.&amp;rdquo; Students were tasked with trying to build some models to make predictions on this dataset. A Jupyter notebook with all the code and results follows here:</description></item><item><title>Hemingway (continued)</title><link>https://kspicer80.github.io/posts/2023-04-15-fitzgerald-hemingway-continued/</link><pubDate>Mon, 10 Apr 2023 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2023-04-15-fitzgerald-hemingway-continued/</guid><description>In my last post, I shared some really simple text classification work on Hemingway, Fitzgerald, and Steinbeck. It was only after posting it that I noticed that Justin Rice beat me to the punch with his post &amp;ldquo;What Makes Hemingway Hemingway?&amp;rdquo; over on &amp;ldquo;The LitCharts Blog&amp;rdquo;. What was terribly curious to me was that Rice showcases some of the key characteristics that one thinks &amp;ldquo;makes Hemingway Hemingway&amp;rdquo;—sentence length, word length, lexical richness, dialogue proportion, parts of speech, characteristic words, and much more.</description></item><item><title>Fitzgerald ... Hemingway ... Steinbeck</title><link>https://kspicer80.github.io/posts/2023-04-07-fitzgerald-hemingway/</link><pubDate>Fri, 07 Apr 2023 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2023-04-07-fitzgerald-hemingway/</guid><description>Lately I have been spending a fair amount of time working on my portfolio for the required &amp;ldquo;Post_Tenure Review&amp;rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,1 focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway.</description></item><item><title>Playing around with ChatGPT</title><link>https://kspicer80.github.io/posts/2022-12-19-playing-around-with-chatgpt/</link><pubDate>Mon, 19 Dec 2022 00:09:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-12-19-playing-around-with-chatgpt/</guid><description>So, like so many (here and here as nice and simple examples—heck, even Graham Harman has gotten into the discussion here) in the computer science field, I have been playing around with the newly-released &amp;ldquo;ChatGPT&amp;rdquo; chatbot released through openAI. It&amp;rsquo;s also that time of the year when we academics start turning to getting all of those syllabi for the upcoming Spring semester ready to go. We all now how onerous it can be to create, say, a reading schedule with dates that we always need to shift when we move from one semester to another.</description></item><item><title>Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century</title><link>https://kspicer80.github.io/posts/2022-09-20-classifying-supreme-court-cases-by-century-with-spacy/</link><pubDate>Mon, 17 Oct 2022 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-09-20-classifying-supreme-court-cases-by-century-with-spacy/</guid><description>Continuing some work with the Supreme Court databases I&amp;rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&amp;rsquo;s grab some data and see what we can do!
There is a really wonderful github repo that contains the .json files of all the Supreme Court cases made available through the CourtListener API.</description></item><item><title>Comparing Stylistic Tendencies of Recent United States Supreme Court Justices (Gorsuch, Kavanaugh, and Barrett)</title><link>https://kspicer80.github.io/posts/2022-07-11-pca-analysis-of-recent-new-justices_21/</link><pubDate>Mon, 11 Jul 2022 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-07-11-pca-analysis-of-recent-new-justices_21/</guid><description>General Introduction (All of the code for this post is available in this repo here.)
Continuing off of the last two posts (here and here), I thought we might continue seeing what we could do with our Supreme Court Opinions dataset(s)—I was also fascinated and inspired by a nice little article on Wikipedia about the &amp;ldquo;Ideological leanings of United States Supreme Court justices,&amp;rdquo; which has some really nice images. I thought one might do a little exploratory work with the opinions of some of the more recently appointed Justices: in particular I wanted to look at the work done so far by Justices Gorsuch, Kavanaugh, and Barrett; perhaps a little PCA work to see if we could work through any potential stylistic similarities between their opinions so far.</description></item><item><title>Topic Modeling the United States Supreme Court Utilizing the Top2Vec Library</title><link>https://kspicer80.github.io/posts/2022-07-07-top2vec-topic-modeling_20/</link><pubDate>Thu, 07 Jul 2022 00:13:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-07-07-top2vec-topic-modeling_20/</guid><description>Here in this post I&amp;rsquo;d like to continue working on the same project used in the previous post (here) while trying out the Top2Vec library). As is so often the case, I came across this library via Dr. William Mattingly&amp;rsquo;s YoutTube channel, who devoted two different videos to using this library (here and here). So let&amp;rsquo;s jump in and see what we can do with this library.
This time around we&amp;rsquo;re using a slightly different dataset that comes Kaggle—it contains all of the USSC opinions from 1970 on.</description></item><item><title>Topic Modeling the United States Supreme Court Surrounding Abortion</title><link>https://kspicer80.github.io/posts/2022-07-06-topic-modeling-the-ussc_19/</link><pubDate>Wed, 06 Jul 2022 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-07-06-topic-modeling-the-ussc_19/</guid><description>General Background (All code from this section is available in this repository here.)
Friday of last week, June 24th, 2022, was a profoundly dark day for a great many of us in the United States. Feeling somewhat helpless as the Supreme Court published the final draft of Dobbs v. Jackson Women&amp;rsquo;s Health Organization, I couldn&amp;rsquo;t help but fall back on old patterns. Not really knowing what else to do—I had a student with whom I had recently read the leaked original draft posted by Politico—I couldn&amp;rsquo;t help but say to her when the opinion came down that I didn&amp;rsquo;t know what else to do other than to get to reading.</description></item><item><title>Linear Regression in the Humanities(?!?!) ... not quite</title><link>https://kspicer80.github.io/posts/2022-06-01-linear-regression-in-the-humanities_18/</link><pubDate>Wed, 01 Jun 2022 00:01:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-06-01-linear-regression-in-the-humanities_18/</guid><description>Working my way through some of the new lessons from Codecademy&amp;rsquo;s new &amp;ldquo;Data Scientist: Natural Language Processing Specialist&amp;rdquo; path, I was returning to some of the lessons on linear regression usage in machine learning contexts. I also happened across a really fantastic post from the &amp;ldquo;LaTeX Ninja&amp;rdquo; on &amp;ldquo;Machine Learning for the Humanities: A Very Short Introduction&amp;rdquo;—I hadn&amp;rsquo;t yet come across this site yet and find it full of all kinds of fantastic little nuggets.</description></item><item><title>Binary Text Classification Fun! ... with some Literary Texts by Willa Cather and Sarah Orne Jewett</title><link>https://kspicer80.github.io/posts/2022-04-10-classification-fun-with-some-literary-texts_10/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-04-10-classification-fun-with-some-literary-texts_10/</guid><description>In my DH journey, the work of Dr. William Mattingly has been something of a constant companion and guide.
His video laying out the steps for a &amp;ldquo;Binary Data Classification&amp;rdquo; was clear and quite clarifying for me in all kinds of ways. The classifier&amp;rsquo;s job in this video was to see if it could tell the difference between the work of Oscar Wilde and Dan Brown. What if we tried a different pair of authors/texts?</description></item><item><title>Using Vector Space Models with Shakespeare's Plays</title><link>https://kspicer80.github.io/posts/2022-03-29-vector-space-models-and-shakespeare_09/</link><pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-03-29-vector-space-models-and-shakespeare_09/</guid><description>Much of the toe-dipping into this new DH field I&amp;rsquo;ve been doing as of late has centered around learning many of the kinds of projects carried out and then turning the methods within those projects onto mew artifacts. A while back I worked my way through Folgert Karsdorp, Mike Kestemont, and Allen Riddell&amp;rsquo;s Humanities Data Analysis: Case Studies with Python. I found a great deal of it thought-provoking and fascinating—especially the chapters devoted to modeling texts with vector spaces and the later chapter on stylometry, which focused on some texts by Hildegard of Bingen and Bernard of Clairvaux.</description></item><item><title>Viral Tweet Classification Project</title><link>https://kspicer80.github.io/posts/2022-03-26-twitter-viral-tweet-classification-project_08/</link><pubDate>Sat, 26 Mar 2022 00:00:00 +0000</pubDate><guid>https://kspicer80.github.io/posts/2022-03-26-twitter-viral-tweet-classification-project_08/</guid><description>I had a bit of fun recently working on a machine learning classification project using some Twitter data (said project coming through Codecademy). The goal was to see if we could write some code to properly detect whether or not a tweet was viral (using the K-Nearest Neighbors algorithm). I also played around with a logistic regression model as well. All the code for the following is available in this repo.</description></item></channel></rss>