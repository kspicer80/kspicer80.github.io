<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content><meta name=description content="Continuing some work with the Supreme Court databases I&amp;rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&amp;rsquo;s grab some data and see what we can do!
There is a really wonderful github repo that contains the .json files of all the Supreme Court cases made available through the CourtListener API."><meta name=keywords content=",python,spaCy,spaCy TextClassifier,text classification,digital humanities,dh,pandas,machine learning,data wrangling,data cleaning,json data"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://kspicer80.github.io/posts/2022-09-20-classifying-supreme-court-cases-by-century-with-spacy/><title>Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century :: Digital Forays — Tracing Paths through the Digital Humanities</title><link rel=stylesheet href=/main.b78c3be9451dc4ca61ca377f3dc2cf2e6345a44c2bae46216a322ef366daa399.css integrity="sha256-t4w76UUdxMphyjd/PcLPLmNFpEwrrkYhajIu82bao5k="><link rel=stylesheet type=text/css href=/css/style.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color><link rel="shortcut icon" href=/favicon.ico><meta name=msapplication-TileColor content><meta itemprop=name content="Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century"><meta itemprop=description content="Continuing some work with the Supreme Court databases I&rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&rsquo;s grab some data and see what we can do!
There is a really wonderful github repo that contains the .json files of all the Supreme Court cases made available through the CourtListener API."><meta itemprop=datePublished content="2022-10-17T00:01:00+00:00"><meta itemprop=dateModified content="2022-10-20T11:16:00+00:00"><meta itemprop=wordCount content="1073"><meta itemprop=image content="https://kspicer80.github.io/"><meta itemprop=keywords content="python,spaCy,spaCy TextClassifier,text classification,digital humanities,dh,pandas,machine learning,data wrangling,data cleaning,json data,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kspicer80.github.io/"><meta name=twitter:title content="Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century"><meta name=twitter:description content="Continuing some work with the Supreme Court databases I&rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&rsquo;s grab some data and see what we can do!
There is a really wonderful github repo that contains the .json files of all the Supreme Court cases made available through the CourtListener API."><meta property="og:title" content="Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century"><meta property="og:description" content="Continuing some work with the Supreme Court databases I&rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&rsquo;s grab some data and see what we can do!
There is a really wonderful github repo that contains the .json files of all the Supreme Court cases made available through the CourtListener API."><meta property="og:type" content="article"><meta property="og:url" content="https://kspicer80.github.io/posts/2022-09-20-classifying-supreme-court-cases-by-century-with-spacy/"><meta property="og:image" content="https://kspicer80.github.io/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-17T00:01:00+00:00"><meta property="article:modified_time" content="2022-10-20T11:16:00+00:00"><meta property="og:site_name" content="Digital Forays"><meta property="article:published_time" content="2022-10-17 00:01:00 +0000 UTC"></head><body><div class=container><header class=header><span class=header__inner><a href=/ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>conda activate</span>
<span class=logo__cursor></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=/posts>Blog</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>6 minutes</p></div><article><h1 class=post-title><a href=https://kspicer80.github.io/posts/2022-09-20-classifying-supreme-court-cases-by-century-with-spacy/>Training a SpaCy Text Classifier on Supreme Court Opinions: Classifying Opinions by Century</a></h1><div class=post-content><p>Continuing some work with the Supreme Court databases I&rsquo;ve been fiddling around with lately, I was wondering if I could get a machine learning model to be able to correctly identify and classify a Supreme Court opinion by the decade in which it was written. So let&rsquo;s grab some data and see what we can do!</p><p>There is a really wonderful <a href=https://github.com/brianwc/bulk_scotus>github repo</a> that contains the .json files of all the Supreme Court cases made available through the <a href=https://www.courtlistener.com/api/>CourtListener API</a>. I forked this repo and then proceeded to do some basic data gathering/wrangling (all the code for the data wrangling and exploratory data analysis (EDA) are available in the the repo folder <a href=https://github.com/kspicer80/spacy_text_cat/tree/main/data_wrangling_and_eda>here</a>) First, our libraries:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> spacy
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> spacy.util <span style=color:#f92672>import</span> minibatch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> spacy.training.example <span style=color:#f92672>import</span> Example
</span></span><span style=display:flex><span>nlp <span style=color:#f92672>=</span> spacy<span style=color:#f92672>.</span>blank(<span style=color:#e6db74>&#39;en&#39;</span>)
</span></span></code></pre></div><p>All of the files are split up into folders by the century and then with subfolders by year. We can thus write a simple function to grab all these files and get them—as usual—into a dataframe:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_jsons_into_dataframe</span>(directory):
</span></span><span style=display:flex><span>    temp_list_of_dfs <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    directory <span style=color:#f92672>=</span> directory
</span></span><span style=display:flex><span>    pathlist <span style=color:#f92672>=</span> Path(directory)<span style=color:#f92672>.</span>rglob(<span style=color:#e6db74>&#39;*.json&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> path <span style=color:#f92672>in</span> pathlist:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> open(path) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>            json_data <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>json_normalize(json<span style=color:#f92672>.</span>loads(f<span style=color:#f92672>.</span>read()))
</span></span><span style=display:flex><span>        temp_list_of_dfs<span style=color:#f92672>.</span>append(json_data)
</span></span><span style=display:flex><span>    combined_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(temp_list_of_dfs, ignore_index<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span>(combined_df)
</span></span></code></pre></div><p>Simple enough, we can then just call this function on all of the different century-named folders:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df_1700s <span style=color:#f92672>=</span> read_jsons_into_dataframe(<span style=color:#e6db74>&#39;1700s)</span>
</span></span></code></pre></div><p>After we do that for all four our centuries, we can just merge them all into one dataframe (oh—and after each of the four were read in we added a <code>label</code> column that had the century in it):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>merged_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat([df_1700s, df_1800s, df_1900s, df_2000s])
</span></span></code></pre></div><p>This gives us a nice dataframe with a shape of <code>(63347, 42)</code>. Each of the CourtListener files has columns for the <code>plain_text</code> of the case along with other columns that give us the same information in HTML: <code>html</code> and <code>html_with_citations</code>. We also need to create a <code>label</code> column that will store the century the case was written.</p><p>After some text cleaning using some of standard data cleaning functions, we could do a little teeny-tiny bit of exploratory EDA on our cleaned-up data:</p><p><img src=/images/imgforblogposts/post_25/figure_1.png alt="Figure 1"></p><p><img src=/images/imgforblogposts/post_25/figure_2_value_counts_of_our_labels.png alt="Figure 2"></p><p>Now, we do have a really sizable data imbalance—we have a ton more examples from the 1800s-2000s than we do from the 1700s. The way I decided to handle this was to simply sample the same number of documents from the 1800s, 1900s, and 2000s that we have for the 1700s—i.e. 135.</p><p>Next we can take all our cleaned-up opinions in our file and separate out the texts and the labels and then process them with spaCy using the <code>nlp</code> function (more information on and documentation about spaCy&rsquo;s TextCategorizer pipeline is available <a href=https://spacy.io/api/textcategorizer>here</a>). We&rsquo;ll write a simple little function to handle everything as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_docs</span>(data, target_file, cats):
</span></span><span style=display:flex><span>    docs <span style=color:#f92672>=</span> DocBin()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> doc, label <span style=color:#f92672>in</span> tqdm(nlp<span style=color:#f92672>.</span>pipe(data, as_tuples<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, disable<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;tagger&#39;</span>, <span style=color:#e6db74>&#39;parser&#39;</span>, <span style=color:#e6db74>&#39;attribute_ruler&#39;</span>, <span style=color:#e6db74>&#39;lemmatizer&#39;</span>]), total<span style=color:#f92672>=</span>len(data)):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> cat <span style=color:#f92672>in</span> cats:
</span></span><span style=display:flex><span>            doc<span style=color:#f92672>.</span>cats[cat] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> cat <span style=color:#f92672>==</span> label <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        docs<span style=color:#f92672>.</span>add(doc)
</span></span><span style=display:flex><span>    docs<span style=color:#f92672>.</span>to_disk(target_file)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> docs
</span></span></code></pre></div><p>With this function, we can then get tinker just slightly with our main dataframe to get everything ready to be fed to the <code>make_docs</code> function above:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_json(<span style=color:#e6db74>&#39;training_json_file.json&#39;</span>, orient<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;records&#39;</span>, encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;utf-8&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sanity check here just make sure everything looks good in the dataframe:</span>
</span></span><span style=display:flex><span>print(df<span style=color:#f92672>.</span>head())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;text&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;cleaned_html&#39;</span>]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;\n&#39;</span>,<span style=color:#e6db74>&#39; &#39;</span>, regex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;label&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;label&#39;</span>]<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;str&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Here we&#39;re randomly sampling only 135 texts from each label:</span>
</span></span><span style=display:flex><span>resampled_df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#39;label&#39;</span>)<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>sample(<span style=color:#ae81ff>135</span>))<span style=color:#f92672>.</span>reset_index(drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Once again, just a quick sanity check of the labels for each text opinion:</span>
</span></span><span style=display:flex><span>cats <span style=color:#f92672>=</span> resampled_df<span style=color:#f92672>.</span>label<span style=color:#f92672>.</span>unique()<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>print(cats)
</span></span></code></pre></div><p>Everything looks good so we can use sklearn&rsquo;s <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html><code>train_test_split</code></a> function to split our data into training and testing sets:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_train, X_valid, y_train, y_valid <span style=color:#f92672>=</span> train_test_split(resampled_df[<span style=color:#e6db74>&#34;text&#34;</span>]<span style=color:#f92672>.</span>values, resampled_df[<span style=color:#e6db74>&#34;label&#34;</span>]<span style=color:#f92672>.</span>values, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.3</span>)
</span></span></code></pre></div><p>Let&rsquo;s see what happens when we feed it a text the model hasn&rsquo;t seen before. Given that the <a href=https://github.com/brianwc/bulk_scotus>bulk_scotus repo</a> only goes up to 2015, why don&rsquo;t we give it a much more recent opinion? (The two recent texts are in the <code>texts_for_testing</code> for the main repo.) We&rsquo;ll read &rsquo;em and see what the model thinks:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tqdm(make_docs(list(zip(X_train, y_train)), <span style=color:#e6db74>&#34;train.spacy&#34;</span>, cats<span style=color:#f92672>=</span>cats))
</span></span><span style=display:flex><span>tqdm(make_docs(list(zip(X_valid, y_valid)), <span style=color:#e6db74>&#34;valid.spacy&#34;</span>, cats<span style=color:#f92672>=</span>cats))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Finished making all the docs!&#34;</span>)
</span></span></code></pre></div><p>Using a very simple little <a href=https://github.com/kspicer80/spacy_text_cat/blob/main/training_script.py>python script</a>, we can set the model training—the results of which look like the following:</p><p><img src=/images/imgforblogposts/post_25/spacy_training_screenshot.png alt=spacy_cli_training_screenshot></p><p>Now we want to do some evaluating of the classifier model we&rsquo;ve created. I selected out a number of different opinions from each of the four centuries and ran them through the model (the full notebook is available <a href=https://github.com/kspicer80/spacy_text_cat/blob/main/model_evaluation.ipynb>here</a>). One could easily clean-up the output here a little bit to make things easier to read—the model outputs numbers for each of the four classes, with a score 1.0 being a high likelihood that the opinion was from that century:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>{<span style=color:#e6db74>&#39;1764_84587&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>7.777257948760052e-09</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>2.8018092301806703e-16</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>9.425196398636101e-20</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1783_84599&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.32349979877471924</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.034033384174108505</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.16195958852767944</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.4805071949958801</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1944_103915&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1880_90030&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1850_86508&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>1.708175368559873e-25</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1764_84586&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.9460902810096741</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.0035104146227240562</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.021581759676337242</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.028817567974328995</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1985_111301&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;2022_opinion_2&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>5.568387912354698e-38</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>5.690646799485532e-28</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>3.485777328789978e-31</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1865_87621&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>2.6655867259250954e-05</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.9999731779098511</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>7.38305203640266e-08</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>5.533585308720168e-12</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1902_95542&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>3.664196701011874e-18</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>5.649902491268908e-18</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>3.246556751151545e-34</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1764_2381788&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.384422242641449</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.038189876824617386</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.2620941698551178</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.31529369950294495</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1920_99495&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>4.156211399347631e-12</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>6.179726227672443e-43</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1898_94785&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>5.021724189773055e-15</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>7.398553538091516e-17</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>1.226735308388623e-24</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1783_84600&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>9.028870096017272e-09</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.044657360615986e-09</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>5.815799231090324e-11</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1963_106601&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;2022_opinion_1&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>2.396220373995437e-43</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>2.923387118178614e-29</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>7.380723387276827e-21</span>},
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;1804_84713&#39;</span>:
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;1700&#39;</span>: <span style=color:#ae81ff>3.133987236392244e-10</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1800&#39;</span>: <span style=color:#ae81ff>1.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;1900&#39;</span>: <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;2000&#39;</span>: <span style=color:#ae81ff>0.0</span>}}
</span></span></code></pre></div><p>Actually, there&rsquo;s a nice little library available through <code>pip</code> that takes a dataframe and export it as a .png (see docs for <code>dataframe-image</code> <a href=https://pypi.org/project/dataframe-image/>here</a>):</p><p><img src=/images/imgforblogposts/post_25/test_table_png_file.png alt=test_table_png_file></p><p>That looks much nicer and way easier to read.</p><p>The model correctly classified 76% of the opinions correctly—13 out of 17. Not bad, I suppose. It would be interesting to see what would happen if we didn&rsquo;t deal with the <a href=https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data>data imbalance</a> problem and simply fed it the 135 samples from the 1700s along with the full data from the 1800s, 1900s, and 2000s. Sounds like a nice little thing to check out when I get some more free time here.</p><p>More to come, as always, I&rsquo;m sure.</p><p>[Update as of Thursday, October 20th, 2022: Increasing the number of samples from the 1800s, 1900s, and 2000s did not result in any increase in terms of accuracy—still 13 out of 17.]</p></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://kspicer80.github.io/tags/python/>python</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/spacy/>spaCy</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/spacy-textclassifier/>spaCy TextClassifier</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/text-classification/>text classification</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/digital-humanities/>digital humanities</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/dh/>dh</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/pandas/>pandas</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/machine-learning/>machine learning</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/data-wrangling/>data wrangling</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/data-cleaning/>data cleaning</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/json-data/>json data</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>1073 Words</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2022-10-17 00:01
(Last updated: 2022-10-20 11:16)</p></div><hr><div class=sharing-buttons><a class=resp-sharing-button__link href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on facebook"><div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://twitter.com/intent/tweet/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on twitter"><div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.tumblr.com/widgets/share/tool?posttype=link&title=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&caption=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&canonicalUrl=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on tumblr"><div class="resp-sharing-button resp-sharing-button--tumblr resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14.563 24c-5.093.0-7.031-3.756-7.031-6.411V9.747H5.116V6.648c3.63-1.313 4.512-4.596 4.71-6.469C9.84.051 9.941.0 9.999.0h3.517v6.114h4.801v3.633h-4.82v7.47c.016 1.001.375 2.371 2.207 2.371h.09c.631-.02 1.486-.205 1.936-.419l1.156 3.425c-.436.636-2.4 1.374-4.156 1.404h-.178l.011.002z"/></svg></div></div></a><a class=resp-sharing-button__link href="mailto:?subject=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&body=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_self rel=noopener aria-label title="Share via email"><div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></div></div></a><a class=resp-sharing-button__link href="https://pinterest.com/pin/create/button/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f&media=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f;description=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century" target=_blank rel=noopener aria-label title="Share on pinterest"><div class="resp-sharing-button resp-sharing-button--pinterest resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M12.017.0C5.396.0.029 5.367.029 11.987c0 5.079 3.158 9.417 7.618 11.162-.105-.949-.199-2.403.041-3.439.219-.937 1.406-5.957 1.406-5.957s-.359-.72-.359-1.781c0-1.663.967-2.911 2.168-2.911 1.024.0 1.518.769 1.518 1.688.0 1.029-.653 2.567-.992 3.992-.285 1.193.6 2.165 1.775 2.165 2.128.0 3.768-2.245 3.768-5.487.0-2.861-2.063-4.869-5.008-4.869-3.41.0-5.409 2.562-5.409 5.199.0 1.033.394 2.143.889 2.741.099.12.112.225.085.345-.09.375-.293 1.199-.334 1.363-.053.225-.172.271-.401.165-1.495-.69-2.433-2.878-2.433-4.646.0-3.776 2.748-7.252 7.92-7.252 4.158.0 7.392 2.967 7.392 6.923.0 4.135-2.607 7.462-6.233 7.462-1.214.0-2.354-.629-2.758-1.379l-.749 2.848c-.269 1.045-1.004 2.352-1.498 3.146 1.123.345 2.306.535 3.55.535 6.607.0 11.985-5.365 11.985-11.987C23.97 5.39 18.592.026 11.985.026L12.017.0z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f&title=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&summary=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&source=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on linkedin"><div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></div></div></a><a class=resp-sharing-button__link href="https://reddit.com/submit/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f&resubmit=true&title=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century" target=_blank rel=noopener aria-label title="Share on reddit"><div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M12 0A12 12 0 000 12a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0012 0zm5.01 4.744c.688.0 1.25.561 1.25 1.249a1.25 1.25.0 01-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968.0 1.754.786 1.754 1.754.0.716-.435 1.333-1.01 1.614a3.111 3.111.0 01.042.52c0 2.694-3.13 4.87-7.004 4.87s-7.004-2.176-7.004-4.87c0-.183.015-.366.043-.534A1.748 1.748.0 014.028 12c0-.968.786-1.754 1.754-1.754.463.0.898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342.0 01.14-.197.35.35.0 01.238-.042l2.906.617a1.214 1.214.0 011.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687.0 1.248-.561 1.248-1.249S9.937 12 9.249 12zm5.5.0c-.687.0-1.248.561-1.248 1.25.0.687.561 1.248 1.249 1.248S16 13.937 16 13.249c0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327.0 00-.231.094.33.33.0 000 .463c.842.842 2.484.913 2.961.913s2.105-.056 2.961-.913a.361.361.0 00.029-.463.33.33.0 00-.464.0c-.547.533-1.684.73-2.512.73-.828.0-1.979-.196-2.512-.73a.326.326.0 00-.232-.095z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.xing.com/app/user?op=share;url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f;title=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century" target=_blank rel=noopener aria-label title="Share on xing"><div class="resp-sharing-button resp-sharing-button--xing resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M18.188.0c-.517.0-.741.325-.927.66.0.0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211.0.375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016.0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894.0 21.686.0h-3.498zM3.648 4.74c-.211.0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016.0.021L1.86 16.051c-.099.188-.093.381.0.529.085.142.239.234.45.234h3.461c.518.0.766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></svg></div></div></a><a class=resp-sharing-button__link href="whatsapp://send?text=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century%20https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on whatsapp"><div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198.0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479.0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87.0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86.0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64.0 5.122 1.03 6.988 2.898a9.825 9.825.0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815.0 0012.05.0C5.495.0.16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882.0 005.683 1.448h.005c6.554.0 11.89-5.335 11.893-11.893a11.821 11.821.0 00-3.48-8.413z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f&t=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century" target=_blank rel=noopener aria-label title="Share on hacker news"><div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M0 24V0h24v24H0zM6.951 5.896l4.112 7.708v5.064h1.583v-4.972l4.148-7.799h-1.749l-2.457 4.875c-.372.745-.688 1.434-.688 1.434s-.297-.708-.651-1.434L8.831 5.896h-1.88z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://telegram.me/share/url?text=Training%20a%20SpaCy%20Text%20Classifier%20on%20Supreme%20Court%20Opinions%3a%20Classifying%20Opinions%20by%20Century&url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2022-09-20-classifying-supreme-court-cases-by-century-with-spacy%2f" target=_blank rel=noopener aria-label title="Share on telegram"><div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"/><polygon points="22 2 15 22 11 13 2 9 22 2"/></svg></div></div></a></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://kspicer80.github.io/posts/2022-12-19-playing-around-with-chatgpt/><span class=button__icon>←</span>
<span class=button__text>Playing around with ChatGPT</span></a></span>
<span class="button next"><a href=https://kspicer80.github.io/posts/2022-08-02-pacman-javascript-introduction/><span class=button__text>(Re)Creating Pacman with Javascript</span>
<span class=button__icon>→</span></a></span></div></div></main></div><footer><div class=footer-social-icons><a href=https://github.com/kspicer80 target=_blank rel=noopener title=Github><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://www.linkedin.com/in/kevin-spicer-61087037/ target=_blank rel=noopener title=Linkedin><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a><a href=mailto:kspicer@stfrancis.edu target=_blank rel=noopener title=Email><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a><a href=https://twitter.com/drkas5 target=_blank rel=noopener title=Twitter><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></div></footer></div><script type=text/javascript src=/bundle.min.205d491810c28f95aa953fae884e1c27abe13fdf93ec63b882d0036b248d4a6282eb2d134e4e7225c6ad6e86db87b08488a361ca4a7383d01fcff43f3d57b9c3.js integrity="sha512-IF1JGBDCj5WqlT+uiE4cJ6vhP9+T7GO4gtADaySNSmKC6y0TTk5yJcatbobbh7CEiKNhykpzg9Afz/Q/PVe5ww=="></script></body></html>