<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content><meta name=description content="Lately I have been spending a fair amount of time working on my portfolio for the required &amp;ldquo;Post_Tenure Review&amp;rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,1 focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway."><meta name=keywords content=",naive bayes classifier,random forest classifier,decision tree algorithm,machine learning,seaborn,scikit-learn,matplotlib,data visualization,confusion matrix,python,spaCy,jupyter,jupyter notebooks,Canvas LMS,Canvas Instructure,data visualization,ernest hemingway,f. scott fitzgerald,john steinbeck,literature,fiction"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://kspicer80.github.io/posts/2023-04-07-fitzgerald-hemingway/><title>Fitzgerald ... Hemingway ... Steinbeck :: Digital Forays — Tracing Paths through the Digital Humanities</title><link rel=stylesheet href=/main.b78c3be9451dc4ca61ca377f3dc2cf2e6345a44c2bae46216a322ef366daa399.css integrity="sha256-t4w76UUdxMphyjd/PcLPLmNFpEwrrkYhajIu82bao5k="><link rel=stylesheet type=text/css href=/css/style.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color><link rel="shortcut icon" href=/favicon.ico><meta name=msapplication-TileColor content><meta itemprop=name content="Fitzgerald ... Hemingway ... Steinbeck"><meta itemprop=description content="Lately I have been spending a fair amount of time working on my portfolio for the required &ldquo;Post_Tenure Review&rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,1 focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway."><meta itemprop=datePublished content="2023-04-07T00:01:00+00:00"><meta itemprop=dateModified content="2023-04-07T00:01:00+00:00"><meta itemprop=wordCount content="1954"><meta itemprop=image content="https://kspicer80.github.io/"><meta itemprop=keywords content="naive bayes classifier,random forest classifier,decision tree algorithm,machine learning,seaborn,scikit-learn,matplotlib,data visualization,confusion matrix,python,spaCy,jupyter,jupyter notebooks,Canvas LMS,Canvas Instructure,data visualization,ernest hemingway,f. scott fitzgerald,john steinbeck,literature,fiction,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kspicer80.github.io/"><meta name=twitter:title content="Fitzgerald ... Hemingway ... Steinbeck"><meta name=twitter:description content="Lately I have been spending a fair amount of time working on my portfolio for the required &ldquo;Post_Tenure Review&rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,1 focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway."><meta property="og:title" content="Fitzgerald ... Hemingway ... Steinbeck"><meta property="og:description" content="Lately I have been spending a fair amount of time working on my portfolio for the required &ldquo;Post_Tenure Review&rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,1 focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway."><meta property="og:type" content="article"><meta property="og:url" content="https://kspicer80.github.io/posts/2023-04-07-fitzgerald-hemingway/"><meta property="og:image" content="https://kspicer80.github.io/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-07T00:01:00+00:00"><meta property="article:modified_time" content="2023-04-07T00:01:00+00:00"><meta property="og:site_name" content="Digital Forays"><meta property="article:published_time" content="2023-04-07 00:01:00 +0000 UTC"></head><body><div class=container><header class=header><span class=header__inner><a href=/ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>conda activate</span>
<span class=logo__cursor></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=/posts>Blog</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>10 minutes</p></div><article><h1 class=post-title><a href=https://kspicer80.github.io/posts/2023-04-07-fitzgerald-hemingway/>Fitzgerald &mldr; Hemingway &mldr; Steinbeck</a></h1><div class=post-content><p>Lately I have been spending a fair amount of time working on my portfolio for the required &ldquo;Post_Tenure Review&rdquo; at my current institution. I spent quite a bit of time canvassing a great deal of the DH/computer programming learning I have acquired over the last couple of years. I gave a somewhat interesting test project version of some more stylometry/text classification work,<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> focusing quite directly on some work another (former) student of mine, William Mastin, and I have been doing on one of his most favorite authors, Ernest Hemingway. It would be absolutely impossible to canvas the interminable discussions we had about &ldquo;Papa&rdquo; as of late, but I figured I could just share some of the computational work that was tangentially related to this endeavor.</p><p>I think the real impetus for much of this computational investigation was due to the fact that, in many of those conversations, William would often draw parallels and comparisons between Hemingway and Fitzgerald (we even read very closely one of my most favorite Fitzgerald stories, &ldquo;Babylon Revisited&rdquo;). I was curious—could one, say, train a machine learning model to tell the difference between a text written by Hemingway and one by Fitzgerald? For sure—and what I still find so fascinating about all of this is that the way in which the models can do this are not really all that &ldquo;complex&rdquo; or &ldquo;complicated&rdquo; or &ldquo;sophisticated&rdquo;—at least, they are definitely not more sophisticated than when a seasoned reader can (perhaps somewhat) intuitively tell the difference immediately between Hemingway&rsquo;s and Fitzgerald&rsquo;s stylistic tendencies. So let&rsquo;s write a little Python code and I&rsquo;ll try to take readers through what&rsquo;s going on along each step of the process.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>The first step is data gathering, so we head over to <a href=https://gutenberg.org/>Project Gutenberg.org</a> to grab texts that are available and in the public domain by both <a href=https://gutenberg.org/ebooks/author/420>Fitzgerald</a> and <a href=https://gutenberg.org/ebooks/author/50533>Hemingway</a>.<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> Once we have some texts that we can use to train and test the classifier models, we can start coding. We will be utilizing one of the go-to machine learning libraries within Python, <a href=https://scikit-learn.org/stable/>sci-kit learn</a>, an absolute staple for those working in machine learning. Thus we start with our import statements (we&rsquo;re also using <a href=https://seaborn.pydata.org/>seaborn</a> and <a href=https://matplotlib.org/>matplotlib</a> again for plotting, pandas for data wrangling, etc. [the <code>load_data</code> function is just a simple function to read in all the text files and keep track of the author of each text]):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> helper_functions <span style=color:#f92672>import</span> load_data
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.naive_bayes <span style=color:#f92672>import</span> MultinomialNB
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> CountVectorizer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> classification_report, confusion_matrix, accuracy_score
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> spacy
</span></span><span style=display:flex><span>nlp <span style=color:#f92672>=</span> spacy<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#39;en_core_web_lg&#39;</span>)
</span></span></code></pre></div><p>Next we call our <code>load data</code> function to load in all of our text files and then convert that into a pandas DataFrame that contains the text of the work (in the <code>text_data</code> column) along with the named author in the <code>label</code> column. We also want to let sklearn know which columns have the &ldquo;text&rdquo; and which one contains the &ldquo;real/true&rdquo; labels for each text:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>text_data, labels <span style=color:#f92672>=</span> load_data(<span style=color:#e6db74>&#39;data&#39;</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(list(zip(text_data, labels)), columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;text_data&#39;</span>, <span style=color:#e6db74>&#39;label&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;text_data&#39;</span>]
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;label&#39;</span>]
</span></span></code></pre></div><p>Then we utilize one of the functions from the sklearn library that takes the dataset and splits it into &ldquo;training&rdquo; and &ldquo;testing&rdquo; sets. The training set will be the data that the model is given to &ldquo;learn&rdquo; what makes a Hemingway text a Hemingway text (and similarly for Fitzgerald); the &ldquo;testing&rdquo; data is just that: those are the texts that the model has never seen before and thus will make predictions on/about. The normal split in machine learning is usually 80% of the data used for training and 20% for testing, but here we&rsquo;re passing a percentage of 30%:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>													X,
</span></span><span style=display:flex><span>													y,
</span></span><span style=display:flex><span>													test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.3</span>,
</span></span><span style=display:flex><span>													random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span></code></pre></div><p>Now that the training and testing sets are split up, we can start to transform all of this text data into what the model can understand, namely, numbers:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Create a bag-of-words representation of the text data</span>
</span></span><span style=display:flex><span>vectorizer <span style=color:#f92672>=</span> CountVectorizer(stop_words<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;english&#39;</span>)
</span></span><span style=display:flex><span>X_train_vec <span style=color:#f92672>=</span> vectorizer<span style=color:#f92672>.</span>fit_transform(X_train)
</span></span><span style=display:flex><span>X_test_vec <span style=color:#f92672>=</span> vectorizer<span style=color:#f92672>.</span>transform(X_test)
</span></span></code></pre></div><p>As seasoned DH folks knows, what the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer><code>CountVectorizer()</code></a> function does is it takes all of the words in the text and converts the whole text file into just a long list of words. (This is often called a <a href=https://en.wikipedia.org/wiki/Bag-of-words_model>&ldquo;bag of words&rdquo; representation</a> because all the program is doing is, quite literally, counting each word and how many times each word appears; everything ends up in a &ldquo;bag&rdquo; because this process disregards grammar and also word order too.) The second and third lines of code just apply this technique/function to both the training and testing sets—for more information, the <code>.fit</code> method is explained in the documentation <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit>here</a> and the <code>.fit_transform</code> <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform>here</a>.</p><p>Once the text files are converted into a matrix (i.e. the data has been <a href=https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/>&ldquo;vectorized&rdquo;</a>), one can then train a model to make predictions on the testing data. For this little project, we&rsquo;ll utilize a widely used algorithm that is based on &ldquo;Bayes&rsquo; theorem,&rdquo; which &ldquo;describes the probability of an event, based on prior knowledge of conditions that might be related to the event.&rdquo;<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> This is a very commonly used model for &ldquo;text classification&rdquo; problems and it thus serves our purposes here well enough.<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> Once the model is instantiated, we can fit it on our data as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>nb <span style=color:#f92672>=</span> MultinomialNB()
</span></span><span style=display:flex><span>nb<span style=color:#f92672>.</span>fit(X_train_vec, y_train)
</span></span></code></pre></div><p>So how accurate is the model on the texts that were set aside for the testing purposes? One of the standard ways to see the accuracy of the model is to use a number of metrics—i.e. &ldquo;precision,&rdquo; &ldquo;recall,&rdquo; &ldquo;f1-score,&rdquo; etc.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup> Sklearn has a built-in function for this, <code>classification_report</code> which quickly provides us with these metrics and scores. Below we&rsquo;ll print out the <code>accuracy_score</code> for the testing data along with the other metrics:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Evaluate the model on the testing set</span>
</span></span><span style=display:flex><span>accuracy <span style=color:#f92672>=</span> nb<span style=color:#f92672>.</span>score(X_test_vec, y_test)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;The accuracy score for this NaiveBayes Classifier is: </span><span style=color:#e6db74>{</span>accuracy<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><p><img src=/images/imgforblogposts/post_30/classification_report_for_f_v_h_problem.png alt=classification_report_for_f_v_h></p><p>These are fantastic scores for the model. Of course, there are also nice and simple ways to visualize the predictions the model has made by utilizing what is called a &ldquo;confusion matrix&rdquo;. This is a simple picture that shows us the number of &ldquo;true positives,&rdquo; &ldquo;true negatives,&rdquo; &ldquo;false positives,&rdquo; and &ldquo;false negatives.&rdquo; The code to produce the plot is, again, rather simple enough to implement:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Predict the class labels for the test set</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> nb<span style=color:#f92672>.</span>predict(X_test_vec)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Compute the confusion matrix</span>
</span></span><span style=display:flex><span>cm <span style=color:#f92672>=</span> confusion_matrix(y_test, y_pred)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create a list of class labels</span>
</span></span><span style=display:flex><span>classes <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;fitzgerald&#39;</span>, <span style=color:#e6db74>&#39;hemingway&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># plot the confusion matrix</span>
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>heatmap(cm,
</span></span><span style=display:flex><span>			annot<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>			fmt<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;d&#39;</span>,
</span></span><span style=display:flex><span>			cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;viridis&#39;</span>,
</span></span><span style=display:flex><span>			xticklabels<span style=color:#f92672>=</span>classes, yticklabels<span style=color:#f92672>=</span>classes)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># add axis labels and title</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Predicted Label&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;True Label&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Confusion Matrix&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p>The plot produced looks as follows:</p><p><img src=/images/imgforblogposts/post_30/cm_for_f_v_h_classification_problem.png alt=confusion_matrix_for_f_v_h></p><p>A classifier with scores like these is considered to be performing extremely well. But what if we wanted to kick the tires on this model just a little bit more by passing it, say, a text by Hemingway that the model has never before encountered, either in training or testing (many machine learning modeling workflows include this as the &ldquo;validation&rdquo; set, a sample to make a prediction on that was not in the training or testing datasets)? Well, let&rsquo;s feed this brand-new (to the model) text and see who it predicts wrote it. We&rsquo;ll ask it to make a prediction about Hemingway&rsquo;s &ldquo;The Snows of Kilimanjaro.&rdquo; Again, easy enough—and the steps are the same (we read in the text file, vectorize it, and then pass it to the model to make a prediction):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Define a new text sample to classify—Hemingway&#39;s &#34;The Snows of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Kilimanjaro&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;test_data\hemingway_snows.txt&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> new_text <span style=color:#f92672>=</span> <span style=color:#960050;background-color:#1e0010> </span>f<span style=color:#f92672>.</span>read() <span style=color:#960050;background-color:#1e0010> </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Transform the new text sample into a bag-of-words representation</span>
</span></span><span style=display:flex><span>new_counts <span style=color:#f92672>=</span> vectorizer<span style=color:#f92672>.</span>transform([new_text])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Use the trained model to predict the label of the new text sample</span>
</span></span><span style=display:flex><span>new_pred <span style=color:#f92672>=</span> nb<span style=color:#f92672>.</span>predict(new_counts)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Print the predicted label</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> new_pred <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> print(<span style=color:#e6db74>&#34;The model predicts that this text is by Hemingway ...&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> print(<span style=color:#e6db74>&#34;The model predicts that this text is by Fitzgerald ...&#34;</span>)
</span></span></code></pre></div><p>This code outputs the following:</p><p><img src=/images/imgforblogposts/post_30/prediction_for_h_snows.png alt=nb_model_prediction_for_snows></p><p>Nice—a perfectly correct prediction. I should say that one could easily wonder just a bit if the binary parameter here in this problem—a text is either by Hemingway or it&rsquo;s not—does come with some starting assumptions that one could tweak slightly if they wanted. What if the comparison was not between Hemingway and Fitzgerald but between Hemingway and someone a reader might consider to already be somewhat &ldquo;closer&rdquo; to Hemingway in terms of style? What about texts by John Steinbeck? Again, we can reuse the code already and simply alter it so that we have the program read in the texts by Steinbeck in the training part of the process. Once again, a very simple Naive Bayes classifier can quite easily distinguish between Hemingway and Steinbeck too:</p><p><img src=/images/imgforblogposts/post_30/classification_report_for_h_v_s_problem.png alt=accuracy_scores_for_nb_models_f_v_h></p><p><img src=/images/imgforblogposts/post_30/cm_for_h_v_steinbeck.png alt=confusion_matrix_for_f_h_and_s></p><p>And, once more, if we pass it a text by Steinbeck (<em>In Dubious Battle</em>) for validation, we can ask for another prediction—and we get:</p><p><img src=/images/imgforblogposts/post_30/prediction_for_s_in_dubious_battle.png alt=in_dubious_battle_prediction></p><p>What I find so curious about this entire process is what I mentioned earlier, the model can seem to figure out who authored what simply by counting words and keeping track of their frequencies—nothing more sophisticated would seem to be required here. There are, of course, far more intricate algorithms and vectorizers that can be used when working with textual data (the &ldquo;term-frequency inverse document frequency,&rdquo; TF-IDF for short, is just one example), but such sophistication seems unnecessary—at least here in this particular case. The frequency counts of words seem to be enough to distinguish between the writing of these authors. It might perhaps go without saying, but I think these developments ask those of us working within the humanities to potentially rethink how we want to talk about something like a writer&rsquo;s &ldquo;style.&rdquo; Those working in literature might love to use all kinds of literary techniques, rhetorical tropes, and much more to discuss a writer&rsquo;s style. The machine would seem to be able to get along just fine by merely(?) counting things. As I say, I think this is incredibly thought-provoking for humanistic study more broadly—and I continue to be amazed with the results.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p> Such work has already been treated on this blog here utilizing work by <a href=https://kspicer80.github.io/posts/2022-03-29-vector-space-models-and-shakespeare_09/>Shakespeare</a>, <a href=https://kspicer80.github.io/posts/2022-04-10-classification-fun-with-some-literary-texts_10/>Willa Cather</a>, and others.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p> All the code for this short project is available in the following <a href=https://github.com/kspicer80/fitzgerald_hemingway>GitHub repo</a>.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p> Many of the works by Hemingway are not in the public domain in the US, but are in Canada. As this strikes me as a perfect case of &ldquo;Fair Use,&rdquo; one can head over <a href="https://www.fadedpage.com/csearch.php?author=Hemingway,%20Ernest">this way</a> for some of those Hemingway works.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p> See Wikipedia&rsquo;s entry on &ldquo;Bayes Theorem&rdquo; <a href=https://en.wikipedia.org/wiki/Bayes%27_theorem>here</a>. The entry on the &ldquo;Naive Bayes Classifier&rdquo; is also available <a href=https://en.wikipedia.org/wiki/Naive_Bayes_classifier>here</a>.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p> The implementation documentation for this in sklearn is available <a href=https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB>here</a>.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p> Of course, one could utilize all the rich information that would come from looking at the author&rsquo;s grammatical tics and preferences. A simple workflow for this would take the texts and extract all of the &ldquo;parts of speech&rdquo; (POS) for each word in each sentence (the <a href=https://spacy.io/>spaCy library</a> is a fantastically awesome workhouse for this kind of thing); once one had &ldquo;POS tagged&rdquo; each sentence, those counts—of nouns, verbs, participles, direct objects (something of a big favorite of Hemingway, in particular), even the number of punctuation marks—could be used in further <a href=https://en.wikipedia.org/wiki/Feature_engineering>&ldquo;feature engineering&rdquo;</a> the model so that it could use those numbers to make predictions. For readers that are interested in how some of the different kinds of classifier handle trying to classify texts by all three authors (Fitzgerald, Hemingway, and Steinbeck), the following <a href=https://github.com/kspicer80/fitzgerald_hemingway/blob/main/grammatical_parsing_for_feature_generation.ipynb>Jupyter notebook</a> has the code and results. (As a tiny teaser here: a standard <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> model&rsquo;s accuracy comes back at 50%, a <a href=https://en.wikipedia.org/wiki/Decision_tree_learning>&ldquo;decision tree&rdquo; classifier</a> hit 83%, and the <a href=https://en.wikipedia.org/wiki/Gradient_boosting>&ldquo;gradient boosting machine&rdquo;</a> model hit perfect accuracy and was able to correctly classify texts by all three authors.)&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://kspicer80.github.io/tags/naive-bayes-classifier/>naive bayes classifier</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/random-forest-classifier/>random forest classifier</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/decision-tree-algorithm/>decision tree algorithm</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/machine-learning/>machine learning</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/seaborn/>seaborn</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/scikit-learn/>scikit-learn</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/matplotlib/>matplotlib</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/data-visualization/>data visualization</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/confusion-matrix/>confusion matrix</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/python/>python</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/spacy/>spaCy</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/jupyter/>jupyter</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/jupyter-notebooks/>jupyter notebooks</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/canvas-lms/>Canvas LMS</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/canvas-instructure/>Canvas Instructure</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/data-visualization/>data visualization</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/ernest-hemingway/>ernest hemingway</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/f.-scott-fitzgerald/>f. scott fitzgerald</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/john-steinbeck/>john steinbeck</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/literature/>literature</a></span>
<span class=tag><a href=https://kspicer80.github.io/tags/fiction/>fiction</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>1954 Words</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2023-04-07 00:01</p></div><hr><div class=sharing-buttons><a class=resp-sharing-button__link href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on facebook"><div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://twitter.com/intent/tweet/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on twitter"><div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.tumblr.com/widgets/share/tool?posttype=link&title=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&caption=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&canonicalUrl=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on tumblr"><div class="resp-sharing-button resp-sharing-button--tumblr resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14.563 24c-5.093.0-7.031-3.756-7.031-6.411V9.747H5.116V6.648c3.63-1.313 4.512-4.596 4.71-6.469C9.84.051 9.941.0 9.999.0h3.517v6.114h4.801v3.633h-4.82v7.47c.016 1.001.375 2.371 2.207 2.371h.09c.631-.02 1.486-.205 1.936-.419l1.156 3.425c-.436.636-2.4 1.374-4.156 1.404h-.178l.011.002z"/></svg></div></div></a><a class=resp-sharing-button__link href="mailto:?subject=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&body=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_self rel=noopener aria-label title="Share via email"><div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></div></div></a><a class=resp-sharing-button__link href="https://pinterest.com/pin/create/button/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f&media=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f;description=Fitzgerald%20...%20Hemingway%20...%20Steinbeck" target=_blank rel=noopener aria-label title="Share on pinterest"><div class="resp-sharing-button resp-sharing-button--pinterest resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M12.017.0C5.396.0.029 5.367.029 11.987c0 5.079 3.158 9.417 7.618 11.162-.105-.949-.199-2.403.041-3.439.219-.937 1.406-5.957 1.406-5.957s-.359-.72-.359-1.781c0-1.663.967-2.911 2.168-2.911 1.024.0 1.518.769 1.518 1.688.0 1.029-.653 2.567-.992 3.992-.285 1.193.6 2.165 1.775 2.165 2.128.0 3.768-2.245 3.768-5.487.0-2.861-2.063-4.869-5.008-4.869-3.41.0-5.409 2.562-5.409 5.199.0 1.033.394 2.143.889 2.741.099.12.112.225.085.345-.09.375-.293 1.199-.334 1.363-.053.225-.172.271-.401.165-1.495-.69-2.433-2.878-2.433-4.646.0-3.776 2.748-7.252 7.92-7.252 4.158.0 7.392 2.967 7.392 6.923.0 4.135-2.607 7.462-6.233 7.462-1.214.0-2.354-.629-2.758-1.379l-.749 2.848c-.269 1.045-1.004 2.352-1.498 3.146 1.123.345 2.306.535 3.55.535 6.607.0 11.985-5.365 11.985-11.987C23.97 5.39 18.592.026 11.985.026L12.017.0z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f&title=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&summary=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&source=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on linkedin"><div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></div></div></a><a class=resp-sharing-button__link href="https://reddit.com/submit/?url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f&resubmit=true&title=Fitzgerald%20...%20Hemingway%20...%20Steinbeck" target=_blank rel=noopener aria-label title="Share on reddit"><div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M12 0A12 12 0 000 12a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0012 0zm5.01 4.744c.688.0 1.25.561 1.25 1.249a1.25 1.25.0 01-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968.0 1.754.786 1.754 1.754.0.716-.435 1.333-1.01 1.614a3.111 3.111.0 01.042.52c0 2.694-3.13 4.87-7.004 4.87s-7.004-2.176-7.004-4.87c0-.183.015-.366.043-.534A1.748 1.748.0 014.028 12c0-.968.786-1.754 1.754-1.754.463.0.898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342.0 01.14-.197.35.35.0 01.238-.042l2.906.617a1.214 1.214.0 011.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687.0 1.248-.561 1.248-1.249S9.937 12 9.249 12zm5.5.0c-.687.0-1.248.561-1.248 1.25.0.687.561 1.248 1.249 1.248S16 13.937 16 13.249c0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327.0 00-.231.094.33.33.0 000 .463c.842.842 2.484.913 2.961.913s2.105-.056 2.961-.913a.361.361.0 00.029-.463.33.33.0 00-.464.0c-.547.533-1.684.73-2.512.73-.828.0-1.979-.196-2.512-.73a.326.326.0 00-.232-.095z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://www.xing.com/app/user?op=share;url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f;title=Fitzgerald%20...%20Hemingway%20...%20Steinbeck" target=_blank rel=noopener aria-label title="Share on xing"><div class="resp-sharing-button resp-sharing-button--xing resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M18.188.0c-.517.0-.741.325-.927.66.0.0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211.0.375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016.0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894.0 21.686.0h-3.498zM3.648 4.74c-.211.0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016.0.021L1.86 16.051c-.099.188-.093.381.0.529.085.142.239.234.45.234h3.461c.518.0.766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></svg></div></div></a><a class=resp-sharing-button__link href="whatsapp://send?text=Fitzgerald%20...%20Hemingway%20...%20Steinbeck%20https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on whatsapp"><div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198.0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479.0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87.0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86.0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64.0 5.122 1.03 6.988 2.898a9.825 9.825.0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815.0 0012.05.0C5.495.0.16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882.0 005.683 1.448h.005c6.554.0 11.89-5.335 11.893-11.893a11.821 11.821.0 00-3.48-8.413z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f&t=Fitzgerald%20...%20Hemingway%20...%20Steinbeck" target=_blank rel=noopener aria-label title="Share on hacker news"><div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" stroke="none"><path d="M0 24V0h24v24H0zM6.951 5.896l4.112 7.708v5.064h1.583v-4.972l4.148-7.799h-1.749l-2.457 4.875c-.372.745-.688 1.434-.688 1.434s-.297-.708-.651-1.434L8.831 5.896h-1.88z"/></svg></div></div></a><a class=resp-sharing-button__link href="https://telegram.me/share/url?text=Fitzgerald%20...%20Hemingway%20...%20Steinbeck&url=https%3a%2f%2fkspicer80.github.io%2fposts%2f2023-04-07-fitzgerald-hemingway%2f" target=_blank rel=noopener aria-label title="Share on telegram"><div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"/><polygon points="22 2 15 22 11 13 2 9 22 2"/></svg></div></div></a></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://kspicer80.github.io/posts/2023-04-15-fitzgerald-hemingway-continued/><span class=button__icon>←</span>
<span class=button__text>Hemingway (continued)</span></a></span>
<span class="button next"><a href=https://kspicer80.github.io/posts/2023-01-13-canvas-live-api-work/><span class=button__text>Interacting with the Canvas Live API</span>
<span class=button__icon>→</span></a></span></div></div></main></div><footer class=footer></footer></div><script type=text/javascript src=/bundle.min.205d491810c28f95aa953fae884e1c27abe13fdf93ec63b882d0036b248d4a6282eb2d134e4e7225c6ad6e86db87b08488a361ca4a7383d01fcff43f3d57b9c3.js integrity="sha512-IF1JGBDCj5WqlT+uiE4cJ6vhP9+T7GO4gtADaySNSmKC6y0TTk5yJcatbobbh7CEiKNhykpzg9Afz/Q/PVe5ww=="></script></body></html>